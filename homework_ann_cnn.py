# -*- coding: utf-8 -*-
"""Homework_ANN_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G9xDAIUyQD0xQu1skyt81sJHMHkDaUht

# Họ và tên: Nguyễn Đình Thông
MSSV: 19146398

# Bài 1: Nhận dạng khuôn mặt sử dụng ANN
"""

#Import Library
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from keras.utils import np_utils
from sklearn.utils import shuffle
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pickle
import tensorflow as tf
import math as m

def plot_history(history_fine):
  f1 = history_fine.history['acc']
  val_f1 = history_fine.history['val_acc']

  loss = history_fine.history['loss']
  val_loss = history_fine.history['val_loss']

  plt.figure(figsize=(8, 8))
  plt.subplot(2, 1, 1)
  plt.plot(f1, label='Acc')
  plt.plot(val_f1, label='Validation Acc')
  plt.legend(loc='lower right')
  plt.title('Accuracy')

  plt.subplot(2, 1, 2)
  plt.plot(loss, label='Loss')
  plt.plot(val_loss, label='Validation Loss')
  plt.legend(loc='upper right')
  plt.title('Loss')
  plt.xlabel('epoch')
  plt.show()

def plot_reg_history(history_fine):
  loss = history_fine.history['loss']
  val_loss = history_fine.history['val_loss']
  plt.subplot(2, 1, 2)
  plt.plot(loss, label='Loss')
  plt.plot(val_loss, label='Validation Loss')
  plt.legend(loc='upper right')
  plt.title('Loss')
  plt.xlabel('epoch')
  plt.show()

# Load Data 
with open('data.pickle', 'rb') as f:
    (x_train, y_train) = pickle.load(f)

# Reshape Data
x_pre = x_train[101]
x_train = x_train[:171]
y_train = y_train[:171]
x_train = x_train.reshape(x_train.shape[0], -1)

# Preprocessing Data
x_train = x_train.astype('float32')
x_train /= 255

# Encoding Y
y_train = np_utils.to_categorical(y_train, 2)

# Shuffe Data
x_train, y_train = shuffle(x_train, y_train)

#Create Model
model = Sequential()
model.add(Dense(10, activation='relu', input_shape = (67500,)))
model.add(Dense(10, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(2, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer =Adam(), metrics=['acc'])

history = model.fit(x_train, y_train, batch_size = 32, epochs = 20, validation_split = 0.2)

plot_history(history)

# Load Test Image
plt.imshow(cv2.cvtColor(x_pre, cv2.COLOR_BGR2RGB))
print(x_pre.shape)
img = x_pre.reshape(1,-1)
img = img.astype('float32')
img /= 255

plt.title("Predict (1: Thong, 0: Not Thong): " + str(np.argmax(model.predict(img))))
plt.imshow(cv2.cvtColor(x_pre, cv2.COLOR_BGR2RGB), cmap=plt.get_cmap('gray'))

"""# Bài 2: ROBOT 2 Bậc tự do"""

#Create Data
from sklearn.preprocessing import StandardScaler
# Define Variables
l1 = 40
l2 = 50
x_train = []
y_train = []

# Create Data
for t1 in np.linspace(-(2 * np.pi), 2 * np.pi, 500):
  for t2 in np.linspace(-(2 * np.pi), 2 * np.pi, 500):
    x = l1*m.cos(t1) + l2*m.cos(t1+t2)
    y = l1*m.sin(t1) + l2*m.sin(t1+t2)
    x_train.append(np.array([x,y]))
    y_train.append(np.array([t1,t2]))

# Convert to array
scaler = StandardScaler()
x_train = np.array(scaler.fit_transform(x_train))
y_train = np.array(y_train)

# Shuffe
x_train, y_train = shuffle(x_train, y_train)

#Create Model
model = Sequential()
model.add(Dense(256, activation='relu', input_shape = (2,)))
model.add(Dense(256, activation='relu'))
model.add(Dense(2, activation='linear'))

model.compile(loss='mse', optimizer =tf.optimizers.Adam(learning_rate=0.0001))

history = model.fit(x_train, y_train, batch_size = 512, epochs = 10, validation_split = 0.2)

plot_reg_history(history)

#Predict
# Input x =90, y = 0
test = scaler.transform(np.array([[90,0]]))
t1 = model.predict(test)[0][0]
t2 = model.predict(test)[0][1]

x = l1*m.cos(t1) + l2*m.cos(t2+t1)
y = l1*m.sin(t1) + l2*m.sin(t2+t1)

print("Predict with input: x = 90, y = 0 : t1 = " + str(t1) + " t2 = "+ str(t2))
print("Check: ")
print(" x = " + str(x) + " y = "+ str(y))

"""# Bài 3: ROBOT 3 Bậc Tự Do"""

from sklearn.preprocessing import StandardScaler
# Define Variables
l1 = 40
l2 = 50
l3 = 20
x_train = []
y_train = []

# Create Data
for t1 in np.linspace(-(2 * np.pi), 2 * np.pi, 100):
  for t2 in np.linspace(-(2 * np.pi), 2 * np.pi, 100):
    for t3 in np.linspace(-(2 * np.pi), 2 * np.pi, 100):
      x = l1*m.cos(t1) + l2*m.cos(t1+t2) + l3*m.cos(t1+t2+t3)
      y = l1*m.sin(t1) + l2*m.sin(t1+t2) + l3*m.sin(t1+t2+t3)
      beta = (t1 + t2 + t3)*180/3.14
      x_train.append(np.array([x,y,beta]))
      y_train.append(np.array([t1,t2,t3]))

# Convert to array
scaler = StandardScaler()
x_train = np.array(scaler.fit_transform(x_train))
y_train = np.array(y_train)

# Shuffe
x_train, y_train = shuffle(x_train, y_train)

#Create Model
model = Sequential()
model.add(Dense(256, activation='relu', input_shape = (3,)))
model.add(Dense(256, activation='relu'))
model.add(Dense(3, activation='linear'))

model.compile(loss='mse', optimizer =tf.optimizers.Adam(learning_rate=0.0001))

history = model.fit(x_train, y_train, batch_size = 512, epochs = 10, validation_split = 0.2)

plot_reg_history(history)

#Predict
# Input x =45, y = 45, beta = 90
test = scaler.transform(np.array([[45,45,90]]))
t1 = model.predict(test)[0][0]
t2 = model.predict(test)[0][1]
t3 = model.predict(test)[0][2]

x = l1*m.cos(t1) + l2*m.cos(t1+t2) + l3*m.cos(t1+t2+t3)
y = l1*m.sin(t1) + l2*m.sin(t1+t2) + l3*m.sin(t1+t2+t3)
beta = (t1 + t2 + t3)*180/3.14

print("Predict with input: x = 45, y = 45, beta = 90: t1 = " + str(t1) + " t2 = "+ str(t2) + " t3 = "+ str(t3))
print("Check: ")
print("x = " + str(x) + " y = "+ str(y)+ " beta = "+ str(beta))

"""# Bài 4: Nhận Dạng Khuôn Mặt Sử Dụng CNN"""

# Load Data 
with open('data.pickle', 'rb') as f:
    (x_train, y_train) = pickle.load(f)

# Reshape Data
x_pre_1 = x_train[50]
x_pre_2 = x_train[120]
x_pre_3 = x_train[210]


# Preprocessing Data
x_train = x_train.astype('float32')
x_train /= 255

# Encoding Y
y_train = np_utils.to_categorical(y_train, 3)

# Shuffe Data
x_train, y_train = shuffle(x_train, y_train)

#Create Model
model = Sequential()
model.add(Conv2D(32, (3,3), activation='relu',kernel_initializer='he_uniform', padding ='same', input_shape = (150,150,3)))
model.add(Conv2D(32, (3,3), activation='relu',kernel_initializer='he_uniform', padding ='same'))
model.add(MaxPooling2D(2,2))

model.add(Conv2D(64, (3,3), activation='relu',kernel_initializer='he_uniform', padding ='same'))
model.add(Conv2D(64, (3,3), activation='relu',kernel_initializer='he_uniform', padding ='same'))
model.add(MaxPooling2D(2,2))

model.add(Conv2D(128, (3,3), activation='relu',kernel_initializer='he_uniform', padding ='same'))
model.add(Conv2D(128, (3,3), activation='relu',kernel_initializer='he_uniform', padding ='same'))
model.add(MaxPooling2D(2,2))

model.add(Flatten())
model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(3, activation='softmax'))
model.summary()

opt = Adam(lr = 0.001)
model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['acc'])
his = model.fit(x_train, y_train, epochs = 20, batch_size = 64, validation_split = 0.2)

plot_history(his)

label = ['Khánh', 'Thông', 'Trâm']

#Predict
plt.title("Predict:  " + label[np.argmax(model.predict(x_pre_1.reshape(1,150,150,3)))])
plt.imshow(cv2.cvtColor(x_pre_1, cv2.COLOR_BGR2RGB), cmap=plt.get_cmap('gray'))

plt.title("Predict:  " + label[np.argmax(model.predict(x_pre_2.reshape(1,150,150,3)))])
plt.imshow(cv2.cvtColor(x_pre_2, cv2.COLOR_BGR2RGB), cmap=plt.get_cmap('gray'))

plt.title("Predict:  " + label[np.argmax(model.predict(x_pre_3.reshape(1,150,150,3)))])
plt.imshow(cv2.cvtColor(x_pre_3, cv2.COLOR_BGR2RGB), cmap=plt.get_cmap('gray'))

img=cv2.imread('/content/Thong1.JPG')
img =img.astype('float32')
img/= 255
img=cv2.resize(img,(150,150))
plt.title("Predict:  " + label[np.argmax(model.predict(img.reshape(1,150,150,3)))])
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), cmap=plt.get_cmap('gray'))

